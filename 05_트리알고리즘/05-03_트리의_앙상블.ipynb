{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33710da0",
   "metadata": {},
   "source": [
    "# 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10cb8d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wine = pd.read_csv('https://bit.ly/wine_csv_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "400965e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = wine[['alcohol', 'sugar', 'pH']]\n",
    "target = wine['class']\n",
    "\n",
    "train_input, test_input, train_target, test_target = train_test_split(\n",
    "    input_data, target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1510f8",
   "metadata": {},
   "source": [
    "---\n",
    "# 앙상블 학습(Ensemble Learning)\n",
    "- `정형 데이터`: 수치형 데이터 등 특정 구조로 저장할 수 있는 데이터. CSV, 데이터베이스, 엑셀 등에 저장하기 쉬운 데이터\n",
    "- `비정형 데이터`: 정형 데이터와 다른 형태의 데이터(이미지, 음악, 텍스트 데이터, ... 등)\n",
    "    - 정형 데이터를 다루는데 가장 좋은 성능을 나타내는 알고리즘이 앙상블 학습임.\n",
    "    - 반면 비정형 데이터는 규칙성을 찾기 어려워, 전통적인 머신러닝 방법으로는 모델을 만들기 까다로움 -> 신경망 알고리즘을 통해 해결"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee72405",
   "metadata": {},
   "source": [
    "---\n",
    "# 랜덤 포레스트\n",
    "- 결정 트리를 여러 개 만들어서 숲을 만드는 방법 -> 각 결정 트리의 예측을 활용하여 최종적인 예측을 만들어냄\n",
    "- `랜덤 포레스트`는 각 트리를 훈련시키기 위한 데이터를 만드는 방법이 독특한데, 이게 중요함\n",
    "    - e.g. 전체 데이터셋이 1000개이고, 트리를 훈련시키기 위해 100개의 데이터를 뽑는다고 할 때, 1000개 중 100개를 복원추출을 통해 뽑아냄\n",
    "    - 이렇게 복원 추출 방식으로 뽑아낸 데이터셋을 `부트스트랩 샘플(bootstrap sample)`이라고 함.\n",
    "- 또한, 랜덤 포레스트는 전체 피쳐들의 개수의 제곱근만큼의 피쳐를 선택하고, 그중에서 최선의 분할을 찾는다.\n",
    "    - e.g. 피쳐 개수가 4개라면 2개의 피쳐를 랜덤하게 고르고, 부트스트랩 샘플을 통해 결정 트리를 학습한다.\n",
    "    - 최선의 분할을 찾는다는 말은 타겟값을 가장 잘 구분할 수 있는(불순도가 낮은) 분할 기준을 찾는다는 것\n",
    "- 사이킷런의 랜덤 포레스트는 기본적으로 `100`개의 결정 트리를 훈련함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a8c21d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9973541965122431\n",
      "0.8903229806766861\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']))\n",
    "print(np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c793a53a",
   "metadata": {},
   "source": [
    "- 요번에는 `cross_validate()`를 통해 교차 검증을 수행하였음\n",
    "    - `train_score`: 훈련셋 기준 점수\n",
    "    - `test_score`: 검증셋 기준 점수 합의 평균\n",
    "    - `n_jobs`는 검증에 사용할 CPU코어 수(병렬 연산)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0c2bb6",
   "metadata": {},
   "source": [
    "피쳐의 중요도를 출력해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2132a006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.23183515 0.50059756 0.26756729]\n"
     ]
    }
   ],
   "source": [
    "rf.fit(train_input, train_target)\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f3da90",
   "metadata": {},
   "source": [
    "👉 랜덤 포레스트는 결정 트리 기반의 앙상블 모델이기 때문에, 결정 트리에서 지원하는 여러 매개변수를 동일하게 지원한다.\n",
    "\n",
    "- 이를테면 `criterion`, `max_depth`, `max_features`, `min_samples_split`, `min_impurity_decrease`, `min_samples_leaf` 등이 있다.\n",
    "- 가장 유용한건 결정 트리처럼 피쳐의 중요도(.`feature_importances_`)도 계산할 수 있다. 이는 각 결정 트리의 중요도를 취합한 값으로 나타내진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b314992d",
   "metadata": {},
   "source": [
    "👉 처음 결정 트리를 통해 출력해본 피쳐의 중요도는 약 `[0.123, 0.87, 0.008]`정도였는데, 지금이랑 비교를 해보자.\n",
    "        \n",
    "- 랜덤 포레스트는 피쳐의 일부를 랜덤하게 선택해서 결정 트리를 훈련하기 떄문에, 그 결과 하나의 피쳐에만 과하게 집중하지 않고, 좀 더 많고 다양한 피쳐가 학습에 기여할 기회를 얻게 되는것과 같다. \n",
    "- 이를 통해 오버피팅을 줄이고 모델의 일반화 성능을 높일 수 있게됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060784ca",
   "metadata": {},
   "source": [
    "👉 `RandomForestClassifier`에는 자체적으로 모델을 평가하는 점수를 얻을 수 있는 기능이 있음.\n",
    "- 랜덤 포레스트는 훈련셋에서 복원 추출을 통해 부트스트랩 샘플을 만들고, 결정 트리를 훈련한다고 했음\n",
    "    - 이 때 각 결정트리마다 샘플에 포함되지 않는 샘플이 있는데(`OOB(Out Of Bag) 샘플`이라고 함), 이를 이용해서 Validation Set처럼 활용하면 좋음. 이를 통해 해당 결정 트리를 '평가'할 수 있게됨\n",
    "    - 이 값을 얻으려면 `oob_score`매개변수를 True로 하면 됨(기본값은 False)\n",
    "- 구체적으로, `oob스코어`의 계산은 다음과 같음\n",
    "    - 부트스트랩 샘플 A 외에 나머지 샘플 집합을 B(OOB 샘플)라고 하자.\n",
    "    - A는 결정트리 1,2,3에서 부트스트랩 샘플로써 사용되었고, B는 사용되지 않았음\n",
    "    - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1aab539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8945545507023283\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state=42)\n",
    "rf.fit(train_input, train_target)\n",
    "print(rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0027e8ea",
   "metadata": {},
   "source": [
    "- 결정 트리를 100그루 만들어도, 최종 스코어는 전체 데이터에 대한 한 개의 OOB스코어만 계산한다고 함(구체적으로는 잘 모르겠음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e415ec",
   "metadata": {},
   "source": [
    "---\n",
    "# 엑스트라 트리(Extra Tree)\n",
    "- 엑스트라 트리는 랜덤 포레스트와 매우 유사하게 동작\n",
    "    - 랜덤 포레스트의 매개변수들을 거의 대부분 동일하게 지원함\n",
    "    - 전체 피쳐 중 일부 피쳐를 랜덤하게 선택하여 노드를 분할하는 점도 동일\n",
    "- 다만 차이점은, 엑스트라 트리는 부트스트랩 샘플을 사용하지 않는다는 점. 즉 각 결정 트리를 만들 때, 전체 훈련 세트를 사용함.\n",
    "    - 그 대신 노드를 분할할 때, 가장 좋은 분할을 찾는게 아니라 무작위로 분할함\n",
    "    - 2장에서 `DecisionTreeClassifier`클래스의 `splitter`매개변수를 `random`으로 설정했었는데, 엑스트라 트리가 사용하는 결정 트리가 `splitter=True`인 결정 트리이다.\n",
    "- (참고)엑스트라 트리의 회귀 버전은 `ExtraTreesRegressor`클래스이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca54da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9974503966084433\n",
      "0.8887848893166506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "et = ExtraTreesClassifier(n_jobs=-1, random_state=42)\n",
    "scores = cross_validate(et, train_input, train_target, \n",
    "                        return_train_score=True, n_jobs=-1)\n",
    "\n",
    "print(np.mean(scores['train_score']))\n",
    "print(np.mean(scores['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a112f3",
   "metadata": {},
   "source": [
    "👉 본 예제에서는 피쳐 개수가 많이 않아 랜덤 포레스트와 엑스트라 트리의 성능차이가 크게 안남\n",
    "\n",
    "- 보통 엑스트라 트리가 무작위성이 더 크기 때문에, 랜덤 포레스트보다 더 많은 결정 트리를 훈련해야한다.\n",
    "- 다만, 엑스트라 트리의 장점은 노드를 랜덤하게 분할하기 때문에 계산 속도가 랜덤 포레스트보다 빠르다.\n",
    "    - 결정 트리에서 시간을 많이 쓴느 부분은 최적의 분할을 찾는데에 많이 쓰는데, 특히 피쳐 개수가 많으면 유독 심해진다. 이걸 무작위로 나누게되면 트리를 훨씬 빨리 구성할 수 있게된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1a7f97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20183568 0.52242907 0.27573525]\n"
     ]
    }
   ],
   "source": [
    "et.fit(train_input, train_target)\n",
    "print(et.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752c75a4",
   "metadata": {},
   "source": [
    "---\n",
    "# 그래디언트 부스팅(Gradient Boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a2ffe8",
   "metadata": {},
   "source": [
    "---\n",
    "# 히스토그램 기반 그래디언트 부스팅(Histogram-based Gradient Boosting)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bb8935",
   "metadata": {},
   "source": [
    "---\n",
    "# QA\n",
    "\n",
    "👉 랜덤 포레스트가 피쳐와 데이터 샘플을 랜덤하게 뽑는 이유가 뭔가요? 랜덤하게 뽑아도 특정 피쳐나 샘플에 편향될 위험이 있지 않을까요?\n",
    "\n",
    "맞습니다. 랜덤성은 보통 다양성을 확보할 수 있는 대표적인 방법이지만, \n",
    "\n",
    "\n",
    "\n",
    "👉 앙상블을 해야하는 이유가 뭘까요?\n",
    "일반적으로 앙상블은 개별 모델로 문제를 해결할 때 발생하는 모델의 편향이나 분산을 줄이기 위한 기법입니다. \n",
    "\n",
    "편향(Bias)과 분산(Variance)은 모델의 예측 오차를 구성하는 핵심 요소로, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Tech_project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
